{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Train model"
      ],
      "metadata": {
        "id": "YtR1GhYwnLnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pix2tex[train] opencv-python-headless gpustat\n",
        "!pip install --upgrade torch~=2.3.0 torchvision~=0.18.0 torchaudio~=2.3.0 torchtext~=0.18.0"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8b8TLiuYkpz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gpustat"
      ],
      "metadata": {
        "id": "1LMgPeHQ7GyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup workspace"
      ],
      "metadata": {
        "id": "Og-ecqlXmzfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "BASE_DIR = Path(\"workspace\")\n",
        "BASE_DIR.mkdir(exist_ok=True)\n",
        "os.chdir(BASE_DIR)"
      ],
      "metadata": {
        "id": "PWYVQAen328h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download resources"
      ],
      "metadata": {
        "id": "xuKiFWel4SGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import concurrent.futures\n",
        "import requests\n",
        "import hashlib\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "def compute_sha256(file_path: Path) -> str:\n",
        "    \"\"\"Compute SHA-256 hash of a file.\"\"\"\n",
        "    sha256 = hashlib.sha256()\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        while chunk := f.read(4096):\n",
        "            sha256.update(chunk)\n",
        "    return sha256.hexdigest()\n",
        "\n",
        "def download_file(url: str, path: Path, expected_hash: str = None, max_retries=3, timeout=10):\n",
        "    \"\"\"Download file with retries and resumption support.\"\"\"\n",
        "    if expected_hash and compute_sha256(path) == expected_hash:\n",
        "        print(f\"{path.name} exists, skipping.\")\n",
        "        return\n",
        "\n",
        "    retries = 0\n",
        "    while retries < max_retries:\n",
        "        try:\n",
        "            print(f\"Downloading {path.name} (Attempt {retries+1}/{max_retries})...\")\n",
        "            headers = {}\n",
        "\n",
        "            if path.exists():\n",
        "                downloaded_size = path.stat().st_size\n",
        "                headers[\"Range\"] = f\"bytes={downloaded_size}-\"\n",
        "\n",
        "            response = requests.get(url, headers=headers, stream=True, timeout=timeout, allow_redirects=True)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            mode = \"ab\" if \"Range\" in headers else \"wb\"\n",
        "            with open(path, mode) as f:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "\n",
        "            print(f\"{path.name} download complete.\")\n",
        "            sha256_hash = compute_sha256(path)\n",
        "            print(f\"{path.name} SHA-256: {sha256_hash}\")\n",
        "            return\n",
        "\n",
        "        except requests.RequestException as e:\n",
        "            retries += 1\n",
        "            print(f\"Retry {retries}/{max_retries} for {path.name} due to {e}...\")\n",
        "            time.sleep(2 ** retries)\n",
        "\n",
        "    print(f\"Failed to download {path.name} after {max_retries} attempts.\")\n",
        "    path.unlink(missing_ok=True)"
      ],
      "metadata": {
        "id": "wkTehrPfmVY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "DATASET_DIR = Path(\"dataset/data\")\n",
        "\n",
        "DATASET_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "download_list = [\n",
        "    (\"https://drive.google.com/uc?id=1QUjX6PFWPa-HBWdcY-7bA5TRVUnbyS1D\", DATASET_DIR / \"pdfmath.txt\"),\n",
        "    (\"https://github.com/lukas-blecher/LaTeX-OCR/releases/download/v0.0.1/weights.pth\", Path(\"weights.pth\"))\n",
        "]\n",
        "\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
        "    futures = [executor.submit(download_file, url, path) for url, path in download_list]\n",
        "    concurrent.futures.wait(futures)"
      ],
      "metadata": {
        "id": "G-BfPR6tq02t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract resources"
      ],
      "metadata": {
        "id": "b1xYVmAH4Vm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "def extract_zip(file_path: Path, extract_to: Path):\n",
        "    print(f\"Extracting {file_path}...\")\n",
        "    with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(f\"Extraction complete: {extract_to}\")"
      ],
      "metadata": {
        "id": "z2QFaTNEs73k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import random\n",
        "\n",
        "IMAGES_DIR = DATASET_DIR / \"images\"\n",
        "\n",
        "IMAGES_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "extract_zip(DATASET_DIR / \"crohme.zip\", DATASET_DIR)\n",
        "extract_zip(DATASET_DIR / \"pdf.zip\", DATASET_DIR)"
      ],
      "metadata": {
        "id": "BSbOa1EBsT-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare data"
      ],
      "metadata": {
        "id": "y-pkffEZ4hZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VAL_DIR = DATASET_DIR / \"valimages\"\n",
        "\n",
        "VAL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "image_files = list(IMAGES_DIR.glob(\"*\"))\n",
        "val_files = set(random.sample(image_files, 1000))\n",
        "\n",
        "for file in val_files:\n",
        "    dest = VAL_DIR / file.name\n",
        "    if not dest.exists():\n",
        "        shutil.move(str(file), str(dest))"
      ],
      "metadata": {
        "id": "VoCRwmqu4Zt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pix2tex.dataset.dataset \\\n",
        "    -i dataset/data/images dataset/data/train \\\n",
        "    -e dataset/data/CROHME_math.txt dataset/data/pdfmath.txt \\\n",
        "    -o dataset/data/train.pkl"
      ],
      "metadata": {
        "id": "y_HGWw-12BaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pix2tex.dataset.dataset \\\n",
        "    -i dataset/data/valimages dataset/data/val \\\n",
        "    -e dataset/data/CROHME_math.txt dataset/data/pdfmath.txt \\\n",
        "    -o dataset/data/val.pkl"
      ],
      "metadata": {
        "id": "ETx2Ha5Y2HPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile colab.yaml\n",
        "backbone_layers: [2, 3, 7]\n",
        "betas: [0.9, 0.999]\n",
        "batchsize: 10\n",
        "bos_token: 1\n",
        "channels: 1\n",
        "data: dataset/data/train.pkl\n",
        "debug: true\n",
        "decoder_args:\n",
        "  attn_on_attn: true\n",
        "  cross_attend: true\n",
        "  ff_glu: true\n",
        "  rel_pos_bias: false\n",
        "  use_scalenorm: false\n",
        "dim: 256\n",
        "encoder_depth: 4\n",
        "eos_token: 2\n",
        "epochs: 50\n",
        "gamma: 0.9995\n",
        "heads: 8\n",
        "id: null\n",
        "load_chkpt: weights.pth\n",
        "lr: 0.001\n",
        "lr_step: 30\n",
        "max_height: 192\n",
        "max_seq_len: 512\n",
        "max_width: 672\n",
        "min_height: 32\n",
        "min_width: 32\n",
        "model_path: checkpoints\n",
        "name: mixed\n",
        "num_layers: 4\n",
        "num_tokens: 8000\n",
        "optimizer: Adam\n",
        "output_path: outputs\n",
        "pad: false\n",
        "pad_token: 0\n",
        "patch_size: 16\n",
        "sample_freq: 2000\n",
        "save_freq: 1\n",
        "scheduler: StepLR\n",
        "seed: 42\n",
        "temperature: 0.2\n",
        "test_samples: 5\n",
        "testbatchsize: 20\n",
        "tokenizer: dataset/tokenizer.json\n",
        "valbatches: 100\n",
        "valdata: dataset/data/val.pkl"
      ],
      "metadata": {
        "id": "5SoXnwTr2Ql1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pix2tex.train --config colab.yaml"
      ],
      "metadata": {
        "id": "nbUPoKL12ZsA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}